# cs224d-deep-learning-for-nlp
Notes, code, and other resources for auditing the course [CS224d: Deep Learning for 
Natural Language Processing](http://cs224d.stanford.edu/).


### Lectures

 - Lecture 2: Simple Word Vector representations: word2vec, GloVe [slides](http://cs224d.stanford.edu/lectures/CS224d-Lecture2.pdf) [video](https://www.youtube.com/watch?v=T8tQZChniMk)
  - [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/projects/glove/)
  - [word2vec](https://code.google.com/p/word2vec/)
  - [Word2vec Tutorial](http://radimrehurek.com/2014/02/word2vec-tutorial), 2014, Radim Řehůřek
  - [Making sense of word2vec](http://radimrehurek.com/2014/12/making-sense-of-word2vec/)
  - [Optimizing word2vec in gensim](http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/)
  - [A GloVe implementation in Python - foldl](http://www.foldl.me/2014/glove-python/)


## Other Resources
  - [Getting Started with Word2Vec and GloVe](http://textminingonline.com/getting-started-with-word2vec-and-glove)

#### word2vec
  - [word2vec explained: deriving Mikolov et al.'s negative-sampling word-embedding method](http://www.cs.bgu.ac.il/~yoavg/publications/negative-sampling.pdf), 2013, Yoav Goldberg and Omer Levy
  - [word2vec](http://www.reddit.com/r/MachineLearning/comments/30m0eb/what_is_the_state_of_the_art_in_language_modeling/)

  - Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient Estimation of Word Representations in Vector Space. In Proceedings of Workshop at ICLR, 2013.
  - Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean, Distributed Representations of Words and Phrases and their Compositionality. In Proceedings of NIPS, 2013.
  - [Embedding-Based Word Similarity](http://irsrv2.cs.biu.ac.il:9998/?word=machine)


#### GloVe
  - [GloVe: Global Vectors for Word Representation](http://nlp.stanford.edu/projects/glove/)
  - [Getting Started with Word2Vec and GloVe](http://textminingonline.com/getting-started-with-word2vec-and-glove)
  
#### Extensions
  - [Scaling Recurrent Neural Network Language Models](http://arxiv.org/pdf/1502.00512v1.pdf), Will Williams, Niranjani Prasad, David Mrva, Tom Ash, Tony Robinson
  - [Embedding-Based Word Similarity](http://irsrv2.cs.biu.ac.il:9998/?word=machine)
  - [Linguistic Regularities in Sparse and Explicit Word Representations](http://www.cs.bgu.ac.il/~yoavg/publications/conll2014analogies.pdf), 2014, Omer Levy and Yoav Goldberg
  
  
### Recurrent Neural Networks

### Theano

  - [Keras: Theano-based Deep Learning library](https://github.com/fchollet/keras)

### General

 - [Deep Learning University](http://memkite.com/deep-learning-bibliography/)
 
 - [GloVe - Global Vectors for Word Representation - Pennington, Socher, Manning 2014](http://blog.mdda.net/ai/2014/10/13/GloVe/)

### What's Wrong with Deep Learning?
 - [What's wrong with convolutional nets?](http://techtv.mit.edu/collections/bcs/videos/30698-what-s-wrong-with-convolutional-nets), 2014, Geoffrey Hinton
 - [Optimizing Neural Networks that Generate Images](http://www.cs.toronto.edu/~tijmen/tijmen_thesis.pdf), 2014, Tiijman Tieleman
 - [Transforming Auto-encoders](http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf), 2011, G. E. Hinton, A. Krizhevsky & S. D. Wang

